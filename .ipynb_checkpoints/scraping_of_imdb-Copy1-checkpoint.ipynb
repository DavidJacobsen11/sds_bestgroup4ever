{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5ca6bc2528b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlogfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'log.csv'\u001b[0m\u001b[0;31m## name your log file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconnector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraping_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wmd776@alumni.ku.dk'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'wmd776@alumni.ku.dk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scraping_class/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logfile, overwrite_log, connector_type, session, path2selenium, n_tries, timeout)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import requests, re, time\n",
    "from bs4 import BeautifulSoup\n",
    "import scraping_class\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "logfile = 'log.csv'## name your log file.\n",
    "connector = scraping_class.Connector(logfile)\n",
    "session = requests.session()\n",
    "session.headers['wmd776@alumni.ku.dk'] = 'wmd776@alumni.ku.dk' \n",
    "session.headers['Amalie Tokkesdal'] = 'Amalie Tokkesdal'\n",
    "session.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/chart/top'\n",
    "number_of_movies = 250\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.ok:\n",
    "    html = response.text\n",
    "else:\n",
    "    print('error')\n",
    "    \n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "link_location = html.split('href=\"')[1:]\n",
    "\n",
    "links = set()\n",
    "\n",
    "\n",
    "for link_loc in link_location:\n",
    "    link = link_loc.split('\"')[0]\n",
    "    if '/title/' in link:\n",
    "        links.add(link) \n",
    "links = ['https://www.imdb.com/'+link for link in links if not 'ref' in link]# add the domain to each link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions we'll use throughout the assigment.\n",
    "\n",
    "We've chosen this approach to make it easier for us to get an overview of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_budget(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Budget:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[0].split(\"$\")[1].replace(\",\", \"\"))\n",
    "        \n",
    "def find_gross(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Cumulative Worldwide Gross:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[0].split(\"$\")[1].replace(\",\", \"\"))\n",
    "        \n",
    "def find_grossUSA(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Gross USA:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[0].split(\"$\")[1].replace(\",\", \"\"))\n",
    "\n",
    "def find_rating(soup):\n",
    "    for i in soup.find(id=\"title-overview-widget\").find_all(\"div\", class_=\"ratingValue\"):\n",
    "        return i.text.strip().split(\"/\")[0]\n",
    "        \n",
    "def find_runtime(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Runtime:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[1].split(\"min\")[0].strip())\n",
    "def find_date(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Release Date:\":\n",
    "            return i.text.strip().split(\":\")[1].split(\"(\")[0].strip()\n",
    "        \n",
    "def find_genre(soup):\n",
    "    for i in soup.find(id=\"title-overview-widget\").find_all(\"div\", class_=\"subtext\"):\n",
    "        if str(i.text.strip().split(\"|\")[2].replace('\\n','').replace(' ','').split(\",\"))[-3]==(')'):\n",
    "            return i.text.strip().split(\"|\")[1].replace('\\n','').replace(' ','').split(\",\")\n",
    "        else:\n",
    "            return i.text.strip().split(\"|\")[2].replace('\\n','').replace(' ','').split(\",\")\n",
    "        \n",
    "#def preparedatetime(dataframe):\n",
    "#    dataframe['datetime'] = pd.to_datetime(dataframe['date'], format = '%d %B %Y')\n",
    "#    dataframe['month'] = dataframe.datetime.dt.month\n",
    "#    dataframe['month'] = dataframe.datetime.dt.day\n",
    "#    dataframe['month'] = dataframe.datetime.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and cleaning the data \n",
    "\n",
    "Here we use our earlier defined functions to make a dictionary of all the data we need from the description page of each movie, ie. title, budget, the cumulative worldwide gross, the rating, the runtime, date and genre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def page_extractor(url):\n",
    "    r, call_id = connector.get(url, \"LOL\")\n",
    "    try:\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        title = soup.select(\"#title-overview-widget > div.vital > div.title_block > div > div.titleBar > div.title_wrapper > h1\")[0].text.split(\"\\xa0\")[0]\n",
    "        budget = find_budget(soup)\n",
    "        cumulative_worldwide_gross=find_gross(soup)\n",
    "        gross_usa=find_grossUSA(soup)\n",
    "        rating = find_rating(soup)\n",
    "        runtime = find_runtime(soup)\n",
    "        date= find_date(soup)\n",
    "        genre = find_genre(soup)\n",
    "    except:\n",
    "        soup = None\n",
    "        title = None\n",
    "        budget = None\n",
    "        cumulative_worldwide_gross= None\n",
    "        gross_usa = None\n",
    "        rating=None\n",
    "        runtime = None\n",
    "        date = None\n",
    "        genre = None\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        #\"year\": year,\n",
    "        \"budget\": budget,\n",
    "        \"url\": url,\n",
    "        \"cumulative_world_gross\": cumulative_worldwide_gross,\n",
    "        \"gross_usa\": gross_usa,\n",
    "        \"rating\": rating,\n",
    "        \"runtime\": runtime,\n",
    "        \"date\": date,\n",
    "        \"genre\": genre\n",
    "    }\n",
    "\n",
    "#Husk at finde titel på engelsk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list and append information from every movie on the list. \n",
    "Remark: We have only chosen top 250 so far, as to not make the coding too slow in progress. If you wish to see the whole list, or a minor part of it, simply change the brackets after 'links'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09cac69f5997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'links' is not defined"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for idx, i in enumerate(links[:15]):\n",
    "    print(idx + 1, \"of\", len(links[:15]))\n",
    "    res.append(page_extractor(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our list into a dataframe, and applying datetime to the releasedate\n",
    "\n",
    "A dataframe is basically just when a list has both several columns and rows, if there's only one row it's an array.\n",
    "\n",
    "Remember to comment on the string lengths need to be over 4 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res).dropna()\n",
    "\n",
    "df = df[df['date'].str.len() > 4]\n",
    "\n",
    "def preparedatetime(dataframe):\n",
    "    dataframe['datetime'] = pd.to_datetime(dataframe['date'], format = '%d %B %Y')\n",
    "    dataframe['year'] = dataframe.datetime.dt.year\n",
    "    dataframe['month'] = dataframe.datetime.dt.month\n",
    "    dataframe['day'] = dataframe.datetime.dt.day\n",
    "    return dataframe\n",
    "\n",
    "df = preparedatetime(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dummies for each genre so we're able to look at their effect individually\n",
    "\n",
    "Here we create an empty set so we're able to add each genre our loop finds. We've chosen a set as this builds an unordered collection of unique elements, so the genres won't be added twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>cumulative_world_gross</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>gross_usa</th>\n",
       "      <th>rating</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>datetime</th>\n",
       "      <th>...</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Family</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Action</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Adventure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000.0</td>\n",
       "      <td>225933435.0</td>\n",
       "      <td>6 March 1998</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>138433435.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>126.0</td>\n",
       "      <td>Good Will Hunting</td>\n",
       "      <td>https://www.imdb.com//title/tt0119217/</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18000000.0</td>\n",
       "      <td>390133212.0</td>\n",
       "      <td>15 January 1982</td>\n",
       "      <td>[Action, Adventure]</td>\n",
       "      <td>248159971.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Jagten på den forsvundne skat</td>\n",
       "      <td>https://www.imdb.com//title/tt0082971/</td>\n",
       "      <td>1982-01-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4500000.0</td>\n",
       "      <td>49219587.0</td>\n",
       "      <td>5 October 2018</td>\n",
       "      <td>[Crime, Thriller]</td>\n",
       "      <td>1193046.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Andhadhun</td>\n",
       "      <td>https://www.imdb.com//title/tt8108198/</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165000000.0</td>\n",
       "      <td>677471339.0</td>\n",
       "      <td>6 November 2014</td>\n",
       "      <td>[Adventure, Drama, Sci-Fi]</td>\n",
       "      <td>188020017.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>https://www.imdb.com//title/tt0816692/</td>\n",
       "      <td>2014-11-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180000000.0</td>\n",
       "      <td>521311860.0</td>\n",
       "      <td>29 August 2008</td>\n",
       "      <td>[Animation, Adventure, Family]</td>\n",
       "      <td>223808164.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>WALL·E</td>\n",
       "      <td>https://www.imdb.com//title/tt0910970/</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1800000.0</td>\n",
       "      <td>9443876.0</td>\n",
       "      <td>2 April 1964</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>9440272.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Dr. Strangelove - eller Hvordan jeg lærte at g...</td>\n",
       "      <td>https://www.imdb.com//title/tt0057012/</td>\n",
       "      <td>1964-04-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>160000000.0</td>\n",
       "      <td>829895144.0</td>\n",
       "      <td>29 July 2010</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "      <td>292576195.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Inception</td>\n",
       "      <td>https://www.imdb.com//title/tt1375666/</td>\n",
       "      <td>2010-07-29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93000000.0</td>\n",
       "      <td>873174218.0</td>\n",
       "      <td>19 December 2001</td>\n",
       "      <td>[Adventure, Drama, Fantasy]</td>\n",
       "      <td>315544750.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Ringenes herre: Eventyret om ringen</td>\n",
       "      <td>https://www.imdb.com//title/tt0120737/</td>\n",
       "      <td>2001-12-19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90000000.0</td>\n",
       "      <td>291465034.0</td>\n",
       "      <td>10 November 2006</td>\n",
       "      <td>[Crime, Drama, Thriller]</td>\n",
       "      <td>132384315.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>151.0</td>\n",
       "      <td>The Departed</td>\n",
       "      <td>https://www.imdb.com//title/tt0407887/</td>\n",
       "      <td>2006-11-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16400000.0</td>\n",
       "      <td>235860116.0</td>\n",
       "      <td>19 January 1990</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>95860116.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Døde poeters klub</td>\n",
       "      <td>https://www.imdb.com//title/tt0097165/</td>\n",
       "      <td>1990-01-19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11000000.0</td>\n",
       "      <td>105664211.0</td>\n",
       "      <td>12 October 1979</td>\n",
       "      <td>[Horror, Sci-Fi]</td>\n",
       "      <td>80931801.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Alien - Den 8. passager</td>\n",
       "      <td>https://www.imdb.com//title/tt0078748/</td>\n",
       "      <td>1979-10-12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  cumulative_world_gross              date  \\\n",
       "0    10000000.0             225933435.0      6 March 1998   \n",
       "1    18000000.0             390133212.0   15 January 1982   \n",
       "2     4500000.0              49219587.0    5 October 2018   \n",
       "3   165000000.0             677471339.0   6 November 2014   \n",
       "4   180000000.0             521311860.0    29 August 2008   \n",
       "5     1800000.0               9443876.0      2 April 1964   \n",
       "7   160000000.0             829895144.0      29 July 2010   \n",
       "8    93000000.0             873174218.0  19 December 2001   \n",
       "10   90000000.0             291465034.0  10 November 2006   \n",
       "12   16400000.0             235860116.0   19 January 1990   \n",
       "14   11000000.0             105664211.0   12 October 1979   \n",
       "\n",
       "                             genre    gross_usa rating  runtime  \\\n",
       "0                 [Drama, Romance]  138433435.0    8.3    126.0   \n",
       "1              [Action, Adventure]  248159971.0    8.4    115.0   \n",
       "2                [Crime, Thriller]    1193046.0    8.4    139.0   \n",
       "3       [Adventure, Drama, Sci-Fi]  188020017.0    8.6    169.0   \n",
       "4   [Animation, Adventure, Family]  223808164.0    8.4     98.0   \n",
       "5                         [Comedy]    9440272.0    8.4     95.0   \n",
       "7      [Action, Adventure, Sci-Fi]  292576195.0    8.8    148.0   \n",
       "8      [Adventure, Drama, Fantasy]  315544750.0    8.8    178.0   \n",
       "10        [Crime, Drama, Thriller]  132384315.0    8.5    151.0   \n",
       "12                 [Comedy, Drama]   95860116.0    8.1    128.0   \n",
       "14                [Horror, Sci-Fi]   80931801.0    8.4    117.0   \n",
       "\n",
       "                                                title  \\\n",
       "0                                   Good Will Hunting   \n",
       "1                       Jagten på den forsvundne skat   \n",
       "2                                           Andhadhun   \n",
       "3                                        Interstellar   \n",
       "4                                              WALL·E   \n",
       "5   Dr. Strangelove - eller Hvordan jeg lærte at g...   \n",
       "7                                           Inception   \n",
       "8                 Ringenes herre: Eventyret om ringen   \n",
       "10                                       The Departed   \n",
       "12                                  Døde poeters klub   \n",
       "14                            Alien - Den 8. passager   \n",
       "\n",
       "                                       url   datetime  ...  Animation  Family  \\\n",
       "0   https://www.imdb.com//title/tt0119217/ 1998-03-06  ...          0       0   \n",
       "1   https://www.imdb.com//title/tt0082971/ 1982-01-15  ...          0       0   \n",
       "2   https://www.imdb.com//title/tt8108198/ 2018-10-05  ...          0       0   \n",
       "3   https://www.imdb.com//title/tt0816692/ 2014-11-06  ...          0       0   \n",
       "4   https://www.imdb.com//title/tt0910970/ 2008-08-29  ...          1       1   \n",
       "5   https://www.imdb.com//title/tt0057012/ 1964-04-02  ...          0       0   \n",
       "7   https://www.imdb.com//title/tt1375666/ 2010-07-29  ...          0       0   \n",
       "8   https://www.imdb.com//title/tt0120737/ 2001-12-19  ...          0       0   \n",
       "10  https://www.imdb.com//title/tt0407887/ 2006-11-10  ...          0       0   \n",
       "12  https://www.imdb.com//title/tt0097165/ 1990-01-19  ...          0       0   \n",
       "14  https://www.imdb.com//title/tt0078748/ 1979-10-12  ...          0       0   \n",
       "\n",
       "    Horror  Romance  Sci-Fi  Crime  Action  Fantasy  Comedy  Adventure  \n",
       "0        0        1       0      0       0        0       0          0  \n",
       "1        0        0       0      0       1        0       0          1  \n",
       "2        0        0       0      1       0        0       0          0  \n",
       "3        0        0       1      0       0        0       0          1  \n",
       "4        0        0       0      0       0        0       0          1  \n",
       "5        0        0       0      0       0        0       1          0  \n",
       "7        0        0       1      0       1        0       0          1  \n",
       "8        0        0       0      0       0        1       0          1  \n",
       "10       0        0       0      1       0        0       0          0  \n",
       "12       0        0       0      0       0        0       1          0  \n",
       "14       1        0       1      0       0        0       0          0  \n",
       "\n",
       "[11 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = set()\n",
    "for i in df[\"genre\"].apply(set).tolist():\n",
    "    for j in i:\n",
    "        categories.add(j)\n",
    "        \n",
    "df2 = pd.concat([df, pd.DataFrame(columns=categories)], axis=1)\n",
    "\n",
    "\n",
    "def df_dummy(df, col):\n",
    "    return df.apply(lambda x: col in x[\"genre\"], axis=1)\n",
    "\n",
    "for i in categories:\n",
    "    df2[i] = df_dummy(df2, i)\n",
    "    df2[i] = pd.get_dummies(df2[i], drop_first = True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to make an OLS regression\n",
    "\n",
    "First we import all the necessary packages for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error as mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-42e43eeec23a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X = np.array(df[['budget',\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m'gross_usa'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'runtime'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.array(df[['budget',\n",
    "        'gross_usa',\n",
    "        'rating',\n",
    "        'runtime',\n",
    "        'year',\n",
    "        'Action',\n",
    "        'Adventure',\n",
    "        'Animation',\n",
    "        'Biography',\n",
    "        'Comedy',\n",
    "        'Crime',\n",
    "        'Documentary',\n",
    "        'Drama',\n",
    "        'Family',\n",
    "        'Fantasy',\n",
    "        'Film-Noir',\n",
    "        'Game-Show',\n",
    "        'History',\n",
    "        'Horror',\n",
    "        'Music',\n",
    "        'Musical',\n",
    "        'Mystery',\n",
    "        'News',\n",
    "        'Reality-TV',\n",
    "        'Romance',\n",
    "        'Sci-Fi',\n",
    "        'Sport',\n",
    "        'Talk-Show',\n",
    "        'Thriller',\n",
    "        'War',\n",
    "        'Western']])\n",
    "\n",
    "y = np.array(df['cumulative_worldwide_gross'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "norm_scaler = StandardScaler().fit(X_train) \n",
    "X_train = norm_scaler.transform(X_train) \n",
    "X_test = norm_scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning\n",
    "\n",
    "From computing the descriptive statistics of RMSE for the train data on  the test and validation data we can conclude we can split the train data and use this to fit the model. This is because the descriptive statistics are quite similar and we therefore presume our model i generalizing enough. (Balanced). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "    return np.sqrt(mse(y_pred, y_true))\n",
    "\n",
    "output=[]\n",
    "\n",
    "for random_state in range(10):\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=random_state)\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    reg.predict(X_test)\n",
    "    \n",
    "    output.append([rmse(reg.predict(X_val), y_val),\n",
    "                  rmse(reg.predict(X_test), y_test)])\n",
    "    \n",
    "print(pd.DataFrame(output, columns=['test', 'validation']))\n",
    "\n",
    "print(pd.DataFrame(output, columns=['test', 'validation']).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5352ae0646fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Splits the data 5 times into evenly sized bins.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_dev' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kfolds = KFold(n_splits=5) #Splits the data 5 times into evenly sized bins. \n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "\n",
    "lambdas = np.logspace(-4,4,12)\n",
    "# outer loop: lambdas\n",
    "mseCV = []\n",
    "for lambda_ in lambdas:    \n",
    "    # inner loop: folds. For each of the folds (Splits),\n",
    "    mseCV_ = []    \n",
    "    for train_idx, val_idx in folds:        \n",
    "        # train model and compute MSE on test fold\n",
    "        pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=3, include_bias=False),\n",
    "                                     StandardScaler(), #Scale into (0,1)\n",
    "                                     Lasso(alpha=lambda_, random_state=1)) #Inizialize the hyperparameter lambda.       \n",
    "        X_train, y_train, = X_dev.iloc[train_idx], y_dev[train_idx] #Selection where we throw in the indices and take out the data\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev[val_idx] \n",
    "        pipe_lassoCV.fit(X_train, y_train)  #Fit the model on the training data, estimation\n",
    "        mseCV_.append(mse(pipe_lassoCV.predict(X_val), y_val))   #Apply the model to the validation data and store it in an empty list\n",
    "    # store result    \n",
    "    mseCV.append(sum(mseCV_)/len(mseCV_)) \n",
    "    \n",
    "# convert to DataFrame\n",
    "lambdaCV = pd.DataFrame(mseCV, index=lambdas)\n",
    "\n",
    "lambdaCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup__ = BeautifulSoup(requests.get(\"https://www.imdb.com//title/tt0042876/ratings\").text, \"html.parser\").select(\"#main > section > div > table:nth-child(14)\")\n",
    "\n",
    "soup__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titles = []\n",
    "for i in soup__[0].find(\"tr\").find_all(\"th\"):\n",
    "    titles.append(i.text)\n",
    "#titles\n",
    "#res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res = []\n",
    "for row in soup__[0].find_all(\"tr\")[1:]:\n",
    "    rows = []\n",
    "    for col in row.find_all(\"td\"):\n",
    "        for col in row.find_all(\"td\")\n",
    "        col = [float(col) for col in row.find_all(\"td\")]\n",
    "        rows.append(col.find(\"div\").text)\n",
    "    res.append(rows)\n",
    "    #res(map(float, rows))\n",
    "    \n",
    "df__ = pd.DataFrame(res, columns=titles)\n",
    "\n",
    "COLS=['gender', 'all ages', '18under', '18to29', '30to44', '45above']\n",
    "df__.columns=COLS\n",
    "\n",
    "df2 = df__.set_index('gender')\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for machine learning\n",
    "\n",
    "Use predictions. But be careful, look at decisions when it is launced only. \n",
    "\n",
    "\n",
    "How predictive are these features for estimating future earnings? You can say what happens to gross whne I have the feature and exclude it. What happens?\n",
    "\n",
    "What model should we use, try the ols or the \n",
    "\n",
    "run the lasso and allow the regularization - check whether the hyperparameter is really close to ols and check to see if all features are included. Check to see if the lasso is redundent for our case. If the lasso doesn't exclude any features and lambda is like ols you could just use ols. \n",
    "\n",
    "Remember to comment on bias. Is there something correlated with the error term?\n",
    "\n",
    "Our data is continous which is why we've used MSE as our accuracy measure. \n",
    "\n",
    "1. \n",
    "\n",
    "The ridge and lasso determines lasso, when we start estimating we could fix it at a certain order but could also make it a hyperparameter. We optimize over these lambdas at our validation set. First we split the data in order to have an honest. the more data you have the less you need for testing. we've chosen a distribution of blabla. With polynomial transformation.\n",
    "\n",
    "2. \n",
    "After we have the data split we make a model. We take all of our polynomial, scaling and our supervised learning model to make it a pipeline. It gives a clean overview of what we've done. \n",
    "\n",
    "3. \n",
    "\n",
    "We have build a pipeline. If we have hyperparameters then we want to optimise these. we split the development into one to fit and one to validate. Subdatasets. We take the one that performs best on the validation data. Because we believe this one will perform best on the test data. \n",
    "\n",
    "We estimate the model with the optimal hyperparameter and can go to the test data now.\n",
    "\n",
    "USE CV, Cross validation. \n",
    "\n",
    "Use cv to find the optimal hyperparameters. Cross validation is the loop thing in range 10. So we take the average best on all of the validation sets. This is to avoid that we've just got a lucky draw. USE CV PLEASE AMALIE TAG DIG SAMMEN. We use it in the inner way to find the hyperparameter. We can also use it in the outer way on the whole set. So we also rotate which has to be the test data each time. So the split of test and development and afterwards in the inner level for the train and validation on the development data. HYPERPARAMETERS ARE ON THE INNER LEVEL.\n",
    "\n",
    "REMEMBER TO CHECK FOR TIME SERIES \n",
    "\n",
    "5. Now we fit the model using all the data in the development set. Afterwards you test it on the test set. \n",
    "\n",
    "If you want to say these features add this much? Then you should just plot the distributions and comment on the similarity. \n",
    "\n",
    "If we asume all are independt and can sample them statically. For each of the test we use the non test data to make our model 10 times. Then we have do this with and without the features we're testing for. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
