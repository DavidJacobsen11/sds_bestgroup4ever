{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create our log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User-Agent': 'python-requests/2.21.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'wmd776@alumni.ku.dk': 'wmd776@alumni.ku.dk', 'Amalie Tokkesdal': 'Amalie Tokkesdal'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import requests, re, time\n",
    "from bs4 import BeautifulSoup\n",
    "import scraping_class\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "logfile = 'the_log.csv'## name your log file.\n",
    "connector = scraping_class.Connector(logfile)\n",
    "session = requests.session()\n",
    "session.headers['wmd776@alumni.ku.dk'] = 'wmd776@alumni.ku.dk' \n",
    "session.headers['Amalie Tokkesdal'] = 'Amalie Tokkesdal'\n",
    "session.headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing HTML with BeautifulSoup\n",
    "\n",
    "When parsing, we took advantage of the pyhton library BeautifulSoup. \n",
    "\n",
    "\"BeautifulSoup makes the html tree navigable. \n",
    "It allows you to:\n",
    "    * Search for elements by tag name and/or by attribute.\n",
    "    * Iterate through them, go up, sideways or down the tree.\n",
    "    * Furthermore it helps you with standard tasks such as extracting raw text from html,\n",
    "    which would be a very tedious task if you had to hardcode it using `.split` commands and using your own regular expressions will be unstable.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMDb advanced search -> feature films -> num votes decending\n",
    "# -> \n",
    "from urllib.request import Request, urlopen\n",
    "url=[]\n",
    "for n in range (1,5000,250):\n",
    "    url.append('https://www.imdb.com/search/title/?title_type=feature&sort=num_votes,desc&count=250&start=' + str(n) + '&ref_=adv_nxt')\n",
    "    #all_url = set(url) # this creates a set of links to the top 5000  most voted movies on IMDb, otherwie it is a list\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#url[0:19]\n",
    "#for elements in all_url: \n",
    "#for elements in url.append:    \n",
    "#requests.get(url.append)\n",
    "#-------------------------------------------------------------------------------------------\n",
    "links = []\n",
    "soup_list=[]\n",
    "import time\n",
    "for x in range(x < 20):\n",
    "    time.sleep(0.5)\n",
    "    response = requests.get(url[x])\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "    else:\n",
    "        print('error')\n",
    "    #req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    #html_page = urlopen(req).read()\n",
    "    #soup = BeautifulSoup(html_page,'html.parser')\n",
    "    soup_list.append(BeautifulSoup(html,'html.parser'))\n",
    "    link_location = html.split('href=\"')[1:]\n",
    "    \n",
    "\n",
    "\n",
    "    for link_loc in link_location:\n",
    "        link = link_loc.split('\"')[0].strip('vote?v=X;k=').strip('?ref_=adv_li_tt')\n",
    "        #link = link_loc.split('\"')[0].strip('tile_type')      -> don't know why this wont work\n",
    "        if '/title/' in link:\n",
    "            links.append(link) \n",
    "    links = ['https://www.imdb.com/'+link for link in links if not 'title_type' in link and not 'ref' in link and not 'plotsummary' in link] # add the domain to each link\n",
    "\n",
    "links = set(links)\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number_of_movies = 5251\n",
    "\n",
    "\n",
    "url=[\"https://www.imdb.com/search/title/?title_type=feature&num_votes=20000,&sort=moviemeter,desc&count=250&start={}&ref_=adv_nxt\".format(pagenum = str(pagenum)) for pagenum in range(1,2251, 250)]\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "for links in url:\n",
    "    time.sleep(0.5)\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "    else:\n",
    "        print('error')\n",
    "    \n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "link_location = html.split('href=\"')[1:]\n",
    "\n",
    "links = set()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link_loc in link_location:\n",
    "    link = link_loc.split('\"')[0]\n",
    "    if '/title/' in link:\n",
    "        links.add(link) \n",
    "links = ['https://www.imdb.com/'+link for link in links if not 'ref' in link]# this adds the domain to each link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_budget(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Budget:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[0].split(\"$\")[1].replace(\",\", \"\"))\n",
    "        \n",
    "def find_gross(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Cumulative Worldwide Gross:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[0].split(\"$\")[1].replace(\",\", \"\"))\n",
    "        \n",
    "def find_grossUSA(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Gross USA:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[0].split(\"$\")[1].replace(\",\", \"\"))\n",
    "\n",
    "def find_rating(soup):\n",
    "    for i in soup.find(id=\"title-overview-widget\").find_all(\"div\", class_=\"ratingValue\"):\n",
    "        return float(i.text.strip().split(\"/\")[0])\n",
    "        \n",
    "def find_runtime(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Runtime:\":\n",
    "            return float(i.text.strip().split(\"\\n\")[1].split(\"min\")[0].strip())\n",
    "def find_date(soup):\n",
    "    for i in soup.find(id=\"titleDetails\").find_all(\"div\", class_=\"txt-block\"):\n",
    "        if i.find().text == \"Release Date:\":\n",
    "            return i.text.strip().split(\":\")[1].split(\"(\")[0].strip()\n",
    "        \n",
    "def find_genre(soup):\n",
    "    for i in soup.find(id=\"title-overview-widget\").find_all(\"div\", class_=\"subtext\"):\n",
    "        if str(i.text.strip().split(\"|\")[2].replace('\\n','').replace(' ','').split(\",\"))[-3]==(')'):\n",
    "            return i.text.strip().split(\"|\")[1].replace('\\n','').replace(' ','').split(\",\")\n",
    "        else:\n",
    "            return i.text.strip().split(\"|\")[2].replace('\\n','').replace(' ','').split(\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing and cleaning the data \n",
    "\n",
    "Here we use our earlier defined functions to make a dictionary of all the data we need from the description page of each movie, ie. title, budget, the cumulative worldwide gross, the rating, the runtime, date and genre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_extractor(url):\n",
    "    r, call_id = connector.get(url, \"LOL\")\n",
    "    try:\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        title = soup.select(\"#title-overview-widget > div.vital > div.title_block > div > div.titleBar > div.title_wrapper > h1\")[0].text.split(\"\\xa0\")[0]\n",
    "        budget = find_budget(soup)\n",
    "        cumulative_worldwide_gross=find_gross(soup)\n",
    "        gross_usa=find_grossUSA(soup)\n",
    "        rating = find_rating(soup)\n",
    "        runtime = find_runtime(soup)\n",
    "        date= find_date(soup)\n",
    "        genre = find_genre(soup)\n",
    "    except:\n",
    "        soup = None\n",
    "        title = None\n",
    "        budget = None\n",
    "        cumulative_worldwide_gross= None\n",
    "        gross_usa = None\n",
    "        rating=None\n",
    "        runtime = None\n",
    "        date = None\n",
    "        genre = None\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        #\"year\": year,\n",
    "        \"budget\": budget,\n",
    "        \"url\": url,\n",
    "        \"cumulative_world_gross\": cumulative_worldwide_gross,\n",
    "        \"gross_usa\": gross_usa,\n",
    "        \"rating\": rating,\n",
    "        \"runtime\": runtime,\n",
    "        \"date\": date,\n",
    "        \"genre\": genre\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list and append information from every movie on the list. \n",
    "Remark: We have only chosen top 250 so far, as to not make the coding too slow in progress. If you wish to see the whole list, or a minor part of it, simply change the brackets after 'links'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 768\n",
      "2 of 768\n",
      "3 of 768\n",
      "4 of 768\n",
      "5 of 768\n",
      "6 of 768\n",
      "7 of 768\n",
      "8 of 768\n",
      "9 of 768\n",
      "10 of 768\n",
      "11 of 768\n",
      "12 of 768\n",
      "13 of 768\n",
      "14 of 768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1ea1e49b3253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-01114708afac>\u001b[0m in \u001b[0;36mpage_extractor\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpage_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LOL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#title-overview-widget > div.vital > div.title_block > div > div.titleBar > div.title_wrapper > h1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\xa0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scraping_class/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, project_name)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'requests'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Determine connector method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# for loop defining number of retries with the requests method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mratelimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# error handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scraping_class/__init__.py\u001b[0m in \u001b[0;36mratelimit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mratelimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"A function that handles the rate of your calls.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sleep one second.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for idx, i in enumerate(links):\n",
    "    print(idx + 1, \"of\", len(links))\n",
    "    res.append(page_extractor(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c08785e04264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our list into a dataframe, and applying datetime to the releasedate\n",
    "\n",
    "A dataframe is basically just when a list has both several columns and rows, if there's only one row it's an array.\n",
    "\n",
    "Remember to comment on the string lengths need to be over 4 characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res).dropna()\n",
    "\n",
    "df = df[df['date'].str.len() > 4]\n",
    "\n",
    "def preparedatetime(dataframe):\n",
    "    dataframe['datetime'] = pd.to_datetime(dataframe['date'], format = '%d %B %Y')\n",
    "    dataframe['year'] = dataframe.datetime.dt.year\n",
    "    dataframe['month'] = dataframe.datetime.dt.month\n",
    "    dataframe['day'] = dataframe.datetime.dt.day\n",
    "    return dataframe\n",
    "\n",
    "df = preparedatetime(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "for i in df[\"genre\"].apply(set).tolist():\n",
    "    for j in i:\n",
    "        categories.add(j)\n",
    "#categories= set(['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family',\n",
    "#                'Fantasy', 'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News',\n",
    "#                'Reality-TV', 'Romance', 'Sci-Fi', 'Sport', 'Talk-Show', 'Thriller'])\n",
    "df2 = pd.concat([df, pd.DataFrame(columns=categories)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_dummy(df, col):\n",
    "    return df.apply(lambda x: col in x[\"genre\"], axis=1)\n",
    "\n",
    "for i in categories:\n",
    "    df2[i] = df_dummy(df2, i)\n",
    "    df2[i] = pd.get_dummies(df2[i], drop_first = True)\n",
    "\n",
    "\n",
    "df2 = df2.set_index(df['title'])\n",
    "\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to make an OLS regression\n",
    "\n",
    "First we import all the necessary packages for this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error as mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df2.drop('cumulative_world_gross','date', 'genre','title', 'url', 'datetime', 'year', 'month', 'day', axis = 1)\n",
    "#categoriess= np.array(categories)\n",
    "\n",
    "X = df2[['budget', 'gross_usa', 'rating', 'runtime', *list(categories)]]\n",
    "y = df2['cumulative_world_gross']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.5, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a scaler from our train data and implement this on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "norm_scaler = StandardScaler().fit(X_train) \n",
    "X_train = norm_scaler.transform(X_train) \n",
    "X_test = norm_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing prediction errors given the target, features and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_input(X_, w_):    \n",
    "    ''' Computes the matrix product between X and w. Note that\n",
    "    X is assumed not to contain a bias/intercept column.'''\n",
    "    return np.dot(X_, w_[1:]) + w_[0]   # We have to add w_[0] separately because this is the constant term. We could also have added a constant term (columns of 1's to X_ and multipliced it to all of w_)\n",
    "\n",
    "def compute_error(y_, X_, w_):\n",
    "    return y_ - net_input(X_, w_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the weights given the prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight(y_, X_, w_, eta):\n",
    "    error = compute_error(y_, X_, w_)    \n",
    "    w_[1:] += eta * (X_.T.dot(error))\n",
    "    w_[0] += eta * (error).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function to compute the mean squared error. Alter the loop so it makes 100 iterations and computes the MSE for test and train after each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def MSE(y_, X_, w_):\n",
    "    error_squared = compute_error(y_, X_, w_)**2\n",
    "    return error_squared.sum() / len(y_)\n",
    "\n",
    "def rmse(y_, X_, w_):\n",
    "    return np.sqrt(MSE(y_, X_, w_))\n",
    "\n",
    "\n",
    "w = np.zeros(X.shape[1]+1)\n",
    "\n",
    "rmse_train = [rmse(y_train, X_train, w)]\n",
    "rmse_test = [rmse(y_test, X_test, w)]\n",
    "\n",
    "for i in range(100):\n",
    "    update_weight(y_train, X_train, w, 10**-3)\n",
    "    \n",
    "    rmse_train.append(rmse(y_train, X_train, w))\n",
    "    rmse_test.append(rmse(y_test, X_test, w))    \n",
    "    \n",
    "    \n",
    "   # brug rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(rmse_train).plot()\n",
    "pd.Series(rmse_test).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking our optimal weights to see the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning\n",
    "\n",
    "From computing the descriptive statistics of RMSE for the train data on  the test and validation data we can conclude we can split the train data and use this to fit the model. This is because the descriptive statistics are quite similar and we therefore presume our model i generalizing enough. (Balanced).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[['budget', 'gross_usa', 'rating', 'runtime', *list(categories)]]\n",
    "\n",
    "def rmse(y_pred, y_true):\n",
    "    return np.sqrt(mse(y_pred, y_true))\n",
    "\n",
    "output=[]\n",
    "\n",
    "for random_state in range(10):\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=1)\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    reg.predict(X_test)\n",
    "    \n",
    "    output.append([rmse(reg.predict(X_val), y_val),\n",
    "                  rmse(reg.predict(X_test), y_test)])\n",
    "    \n",
    "print(pd.DataFrame(output, columns=['test', 'validation']))\n",
    "\n",
    "print(pd.DataFrame(output, columns=['test', 'validation']).describe())\n",
    "\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the genres we have dummy variables, which shouldn't be scaled or made into polynomial features. For this reason our piline only adds these attributes to the first NUMMER columns and only creates the lasso for all of the features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfolds = KFold(n_splits=10) #Splits the data 10 times into evenly sized bins. \n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "\n",
    "lambdas = np.logspace(-4,4,12)\n",
    "# outer loop: lambdas\n",
    "mseCV = []\n",
    "perform = []\n",
    "for lambda_ in lambdas:    \n",
    "    # inner loop: folds. For each of the folds (Splits),\n",
    "    mseCV_ = []    \n",
    "    for train_idx, val_idx in folds:        \n",
    "        # train model and compute MSE on test fold\n",
    "        pipe_lassoCV = make_pipeline(ColumnTransformer(\n",
    "                                    [(\"Continous\", make_pipeline(\n",
    "                                         StandardScaler(),\n",
    "                                         PolynomialFeatures()\n",
    "                                     ), [1,3]), \n",
    "                                      (\"\", 'passthrough', [3,4,5,6,7,8,9,10])\n",
    "                                     ]),\n",
    "                                    Lasso(alpha=lambda_, random_state=1))\n",
    "        X_train, y_train, = X_dev.iloc[train_idx], y_dev[train_idx] #Selection where we throw in the indices and take out the data\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev[val_idx] \n",
    "        pipe_lassoCV.fit(X_train, y_train)  #Fit the model on the training data, estimation\n",
    "        mseCV_.append(mse(pipe_lassoCV.predict(X_val), y_val))   #Apply the model to the validation data and store it in an empty list\n",
    "    #y_val_pred = pipe_lassoCV.predict(X_val)\n",
    "    #y_train_pred = pipe_lassoCV.predict(X_train)\n",
    "    #y_test_pred = pipe_lassoCV.predict(X_test)\n",
    "    #perform.append(mse(y_pred, y_val))\n",
    "    # store result    \n",
    "    mseCV.append(sum(mseCV_)/len(mseCV_)) \n",
    "    \n",
    "# convert to DataFrame\n",
    "lambdaCV = pd.DataFrame(mseCV, index=lambdas)\n",
    "\n",
    "#lambdaCV\n",
    "\n",
    "optimal_lambda = lambdaCV.mean(axis=1).nsmallest(1)\n",
    "optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "pipe_lassoCV = make_pipeline(PolynomialFeatures(include_bias=False), \n",
    "                             StandardScaler(),\n",
    "                             Lasso(alpha=optimal_lambda.index[0], random_state=1))\n",
    "pipe_lassoCV.fit(X_dev,y_dev)\n",
    "\n",
    "train_scores, test_scores = \\\n",
    "    validation_curve(estimator=pipe_lassoCV,\n",
    "                     X=X_train,\n",
    "                     y=y_train,\n",
    "                     param_name='lasso__alpha',\n",
    "                     param_range=lambdas,\n",
    "                     scoring='neg_mean_squared_error',                 \n",
    "                     cv=3)\n",
    "\n",
    "mse_score = pd.DataFrame({'Train':-train_scores.mean(axis=1),\n",
    "                          'Validation':-test_scores.mean(axis=1),\n",
    "                          'lambda':lambdas})\\\n",
    "              .set_index('lambda')   \n",
    "print(mse_score.Validation.nsmallest(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(y_train_pred,  y_train_pred - y_train,\n",
    "             c='steelblue', marker='o', edgecolor='white',\n",
    "             label='Training data')\n",
    "plt.scatter(y_test_pred,  y_test_pred - y_test,\n",
    "             c='limegreen', marker='s', edgecolor='white',\n",
    "            label='Test data')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper left')\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color='black', lw=2)\n",
    "plt.xlim([-10, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for machine learning\n",
    "\n",
    "Use predictions. But be careful, look at decisions when it is launced only. \n",
    "\n",
    "\n",
    "How predictive are these features for estimating future earnings? You can say what happens to gross whne I have the feature and exclude it. What happens?\n",
    "\n",
    "What model should we use, try the ols or the \n",
    "\n",
    "run the lasso and allow the regularization - check whether the hyperparameter is really close to ols and check to see if all features are included. Check to see if the lasso is redundent for our case. If the lasso doesn't exclude any features and lambda is like ols you could just use ols. \n",
    "\n",
    "Remember to comment on bias. Is there something correlated with the error term?\n",
    "\n",
    "Our data is continous which is why we've used the root squared mean error (RMSE) as our accuracy measure. \n",
    "\n",
    "1. \n",
    "\n",
    "The ridge and lasso determines lasso, when we start estimating we could fix it at a certain order but could also make it a hyperparameter. We optimize over these lambdas at our validation set. First we split the data in order to have an honest. the more data you have the less you need for testing. we've chosen a distribution of blabla. With polynomial transformation.\n",
    "\n",
    "2. \n",
    "After we have the data split we make a model. We take all of our polynomial, scaling and our supervised learning model to make it a pipeline. It gives a clean overview of what we've done. \n",
    "\n",
    "3. \n",
    "\n",
    "We have build a pipeline. If we have hyperparameters then we want to optimise these. we split the development into one to fit and one to validate. Subdatasets. We take the one that performs best on the validation data. Because we believe this one will perform best on the test data. \n",
    "\n",
    "We estimate the model with the optimal hyperparameter and can go to the test data now.\n",
    "\n",
    "USE CV, Cross validation. \n",
    "\n",
    "Use cv to find the optimal hyperparameters. Cross validation is the loop thing in range 10. So we take the average best on all of the validation sets. This is to avoid that we've just got a lucky draw. USE CV PLEASE AMALIE TAG DIG SAMMEN. We use it in the inner way to find the hyperparameter. We can also use it in the outer way on the whole set. So we also rotate which has to be the test data each time. So the split of test and development and afterwards in the inner level for the train and validation on the development data. HYPERPARAMETERS ARE ON THE INNER LEVEL.\n",
    "\n",
    "REMEMBER TO CHECK FOR TIME SERIES \n",
    "\n",
    "5. Now we fit the model using all the data in the development set. Afterwards you test it on the test set. \n",
    "\n",
    "If you want to say these features add this much? Then you should just plot the distributions and comment on the similarity. \n",
    "\n",
    "If we asume all are independt and can sample them statically. For each of the test we use the non test data to make our model 10 times. Then we have do this with and without the features we're testing for. \n",
    "\n",
    "\n",
    "\n",
    "A comprehensive guide for how to earn money on movies in hollywood, trying to see which feautures affect the gross most and if you want a surtain audience you should make this genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
